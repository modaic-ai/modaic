{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3dd82f",
   "metadata": {},
   "source": [
    "# Context\n",
    "Example: The Table and TableSchema class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modaic.context.base import ContextSchema, Molecular\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from typing import ClassVar, Type, Optional\n",
    "import duckdb\n",
    "\n",
    "\n",
    "class Table(Context):\n",
    "    context_class: ClassVar[str] = \"Table\"\n",
    "    name: str\n",
    "    num_rows: int\n",
    "\n",
    "\n",
    "class Table(Molecular):\n",
    "    \"\"\"\n",
    "    A molecular context object that represents a table. Can be queried with SQL.\n",
    "    \"\"\"\n",
    "\n",
    "    schema: ClassVar[Type[ContextSchema]] = TableSchema\n",
    "\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, name: str, num_rows: int = 100, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Table context object.\n",
    "\n",
    "        Args:\n",
    "            df: The dataframe to represent as a table.\n",
    "            name: The name of the table.\n",
    "            **kwargs: Additional keyword arguments to pass to the Molecular context object.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self._df = df\n",
    "        self.name = name\n",
    "        self.num_rows = num_rows\n",
    " \n",
    "\n",
    "    def query(self, query: str):  # TODO: add example\n",
    "        \"\"\"\n",
    "        Queries the table. All queries run should refer to the table as `this` or `This`\n",
    "        \"\"\"\n",
    "        return duckdb.query_df(self._df, \"this\", query).to_df()\n",
    "\n",
    "    def markdown(self) -> str:  # TODO: add example\n",
    "        \"\"\"\n",
    "        Converts the table to markdown format.\n",
    "        Returns a markdown representation of the table with the table name as header.\n",
    "        \"\"\"\n",
    "        content = \"\"\n",
    "        content += f\"Table name: {self.name}\\n\"\n",
    "\n",
    "        # Add header row\n",
    "        columns = [str(col) for col in self._df.columns]\n",
    "        content += \"| \" + \" | \".join(columns) + \" |\\n\"\n",
    "\n",
    "        # Add header separator\n",
    "        content += \"| \" + \" | \".join([\"---\"] * len(columns)) + \" |\\n\"\n",
    "\n",
    "        # Add data rows\n",
    "        for _, row in self._df.iterrows():\n",
    "            row_values = []\n",
    "            for value in row:\n",
    "                if pd.isna(value) or value is None:\n",
    "                    row_values.append(\"\")\n",
    "                else:\n",
    "                    row_values.append(str(value))\n",
    "            content += \"| \" + \" | \".join(row_values) + \" |\\n\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    def readme(self):\n",
    "        \"\"\"\n",
    "        readme method for table. Returns a markdown representation of the table.\n",
    "\n",
    "        Example:\n",
    "            ```python\n",
    "            >>> df = pd.DataFrame({\"Column1\": [1, 2, 3], \"Column2\": [4, 5, 6], \"Column3\": [7, 8, 9]})\n",
    "            >>> table = Table(df, name=\"table\")\n",
    "            >>> table.readme()\n",
    "            \"Table name: table\\n\"\n",
    "            \" | Column1 | Column2 | Column3 | \\n\"\n",
    "            \" | --- | --- | --- | \\n\"\n",
    "            \" | 1 | 2 | 3 | \\n\"\n",
    "            \" | 4 | 5 | 6 | \\n\"\n",
    "            \" | 7 | 8 | 9 | \\n\"\n",
    "            ```\n",
    "        \"\"\"\n",
    "        return self.markdown()\n",
    "\n",
    "    def embedme(self):\n",
    "        \"\"\"\n",
    "        embedme method for table. Returns a markdown representation of the table.\n",
    "        \"\"\"\n",
    "        return self.markdown()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        file: str | BytesIO,\n",
    "        name: Optional[str] = None,\n",
    "        metadata: dict = {},\n",
    "        **kwargs,\n",
    "    ):\n",
    "        df = pd.read_csv(file)\n",
    "        return cls(df, name, metadata, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00027ef",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "You can do alot with ContextSchema subclasses and the different database integrations modaic provides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b1b91",
   "metadata": {},
   "source": [
    "## Vector Database Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baae22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "import os\n",
    "from modaic import Indexer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from modaic.databases import VectorDatabase, MilvusVDBConfig, SearchResult, SQLDatabase, SQLiteConfig\n",
    "from modaic.indexing import PineconeReranker, Embedder\n",
    "from modaic.context import Text, TextSchema, Filter\n",
    "\n",
    "vector_db_config = MilvusVDBConfig(\n",
    "    host=\"localhost\",\n",
    "    port=19530,\n",
    "    collection_name=\"table_rag\",\n",
    ")\n",
    "\n",
    "embedder = Embedder(model=\"openai/text-embedding-3-small\")\n",
    "vector_database = VectorDatabase(\n",
    "    config=vector_db_config,\n",
    "    embedder=embedder,\n",
    "    payload_schema=Text.schema,\n",
    ")\n",
    "\n",
    "t1 = Table.from_csv(\"data/t1.csv\", name = \"budget1\", num_rows = 100)\n",
    "t2 = Table.from_csv(\"data/t2.csv\", name = \"budget2\", num_rows = 200)\n",
    "t3 = Table.from_csv(\"data/t3.csv\", name = \"budget3\", num_rows = 900)\n",
    "\n",
    "records = [t1, t2]\n",
    "\n",
    "vector_database.add_records(\"table_rag\", records, batch_size=10000)\n",
    "\n",
    "embedding = embedder(\"2025 budget\")\n",
    "\n",
    "filter = TableSchema.num_rows > 100\n",
    "results = vector_database.search(\"table_rag\", embedding, 1, filter)\n",
    "# reuslts will will be a list of SearchResult(score: float, result: TableSchema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065801e",
   "metadata": {},
   "source": [
    "## Graph Database Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c201b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modaic.databases import GraphDatabase, Neo4jConfig\n",
    "from modaic.context import Relationship\n",
    "\n",
    "config = Neo4jConfig(\n",
    "    host=\"localhost\",\n",
    "    port=7687,\n",
    "    username=\"neo4j\",\n",
    "    password=\"password\",\n",
    "    database=\"neo4j\",\n",
    "    driver=\"neo4j\",\n",
    "    driver_args={},\n",
    "    driver_kwargs={},\n",
    ")\n",
    "\n",
    "graph_db = GraphDatabase(config)\n",
    "\n",
    "e1 = t1 >> Relationship(label=\"DERIVED_FROM\") >> t2\n",
    "\n",
    "e2 = t1 << Relationship(label=\"SIMILAR\") >> t3\n",
    "\n",
    "e1.save(graph_db)\n",
    "e2.save(graph_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01eec1",
   "metadata": {},
   "source": [
    "## Config\n",
    "Stores static configuration parameters for an agent. (What params will change the behavior/accuracy of the expiriment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from modaic import PrecompiledConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TableAgentConfig(PrecompiledConfig):\n",
    "    max_num_rows: int = 100\n",
    "    embedding_model: str = \"openai/text-embedding-3-small\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243c8f9",
   "metadata": {},
   "source": [
    "## Indexer\n",
    "Ingest and queries over data to feed into the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c99c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modaic\n",
    "from modaic import Embedder\n",
    "from modaic.context import Table, TableSchema\n",
    "from modaic.databases import VectorDatabase, VectorDBConfig\n",
    "\n",
    "class TableIndexer(modaic.Indexer):\n",
    "    def __init__(self, config: TableAgentConfig, vdb_config: VectorDBConfig):\n",
    "        super().__init__(config)\n",
    "        self.vdb_config = vdb_config\n",
    "        self.embedder = Embedder(config.embedding_model)\n",
    "        self.vdb = VectorDatabase(vdb_config, self.embedder)\n",
    "\n",
    "    def ingest(self, table: Table):\n",
    "        self.vdb.add_records(table.name, [table], batch_size=10000)\n",
    "    def query(self, query: str):\n",
    "        embedding = self.embedder(query)\n",
    "        results = self.vdb.search(embedding, 1, Filter(TableSchema.num_rows > self.max_num_rows))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f86dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modaic import PrecompiledAgent\n",
    "import dspy\n",
    "\n",
    "class TableAgent(PrecompiledAgent):\n",
    "    def __init__(self, config: TableAgentConfig, indexer: TableIndexer):\n",
    "        super().__init__(config, indexer=indexer)\n",
    "        self.summarizer = dspy.Predict(\"table -> summary\")\n",
    "    \n",
    "    def forward(self, question: str):\n",
    "        results = self.indexer.query(question)\n",
    "        return self.summarizer(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b0b74",
   "metadata": {},
   "source": [
    "# Pushing Frameworks to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deedd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataset import ExampleDataset\n",
    "dataset = ExampleDataset()\n",
    "\n",
    "config = PrecompiledConfig(max_num_rows=100)\n",
    "vdb_config = VectorDBConfig(\n",
    "    host=\"localhost\",\n",
    "    port=19530,\n",
    ")\n",
    "embedder = Embedder(model=\"openai/text-embedding-3-small\")\n",
    "vector_database = VectorDatabase(vdb_config, embedder)\n",
    "indexer = TableIndexer(vdb_config, embedder, max_num_rows=100)\n",
    "agent = TableAgent(config, indexer)\n",
    "\n",
    "agent.forward(\"What is the total budget for the year?\")\n",
    "\n",
    "tp = dspy.MIPROv2(\n",
    "    metric=dspy.evaluate.SemanticF1(decompositional=True), auto=\"medium\", num_threads=24\n",
    ")\n",
    "\n",
    "tp.compile(agent, trainset=dataset, max_bootstrapped_demos=2, max_labeled_demos=2)\n",
    "\n",
    "agent.push_to_hub(\"tytodd/table-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc11f6",
   "metadata": {},
   "source": [
    "# Load Framework from Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec15e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modaic import AutoAgent, AutoIndexer\n",
    "\n",
    "indexer = AutoIndexer.from_precompiled(\n",
    "    \"tytodd/table-indexer\",\n",
    "    vdb_config=VectorDBConfig(host=\"localhost\", port=19530),\n",
    ")\n",
    "\n",
    "agent = AutoAgent.from_precompiled(\"tytodd/table-agent\", indexer=indexer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
